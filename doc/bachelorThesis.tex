\documentclass[11pt]{article}
\usepackage[a4paper, hmargin={2.8cm, 2.8cm}, vmargin={2.5cm, 2.5cm}]{geometry}
\usepackage{eso-pic} % \AddToShipoutPicture
\usepackage{graphicx} % \includegraphics
\usepackage{listings}
\usepackage{setspace}
\usepackage{cite}
\usepackage{stmaryrd}
\usepackage{fixltx2e}
\usepackage{amsmath}
\usepackage{tabu}
\usepackage{geometry}

\lstset{
  mathescape,
  %moredelim=[is][\underbar]{_}{_}
}

\lstdefinelanguage{Futhark}{
  keywords={fun,int,if,then,else,let,in},
  keywordstyle=\color{blue!40!black}\bfseries,
  identifierstyle=\color{green!40!black},
}

\definecolor{Background}{rgb}{0.98,0.98,0.98}
\lstset{
    numbers=left,
    numberstyle=\footnotesize,
    numbersep=1em,
    xleftmargin=1em,
    framextopmargin=2em,
    framexbottommargin=2em,
    showspaces=false,
    showtabs=false,
    showstringspaces=false,
    frame=l,
    tabsize=4,
    % Basic
    basicstyle=\ttfamily\footnotesize\setstretch{1},
    backgroundcolor=\color{Background}
}

\author{
  \Large{Anna Sofie Kiehn \& Henriks Urms}\\
  \\ \textit{Supervisor:} Martin Elsman
  % \texttt{a.kiehn89@gmail.com} \\
  %\\ \texttt{a.kiehn89@gmail.com} \\ \\
  %\Large{Henriks Urms}
  %\\ \texttt{urmshenrik@gmail.com}
}

\title{
  \vspace{5cm}
  \Huge{Bachelor's thesis} \\
  \Large{Compiling TAIL to Futhark}
}

\begin{document}
%\renewcommand{\arraystretch}{1.2}

\newcommand{\evals}[1]{\llbracket #1 \rrbracket}

%% Change `ku-farve` to `nat-farve` to use SCIENCE's old colors or
%% `natbio-farve` to use SCIENCE's new colors and logo.
\AddToShipoutPicture*{\put(0,0){\includegraphics*[viewport=0 0 700 600]{include/natbio-farve}}}
\AddToShipoutPicture*{\put(0,602){\includegraphics*[viewport=0 600 700 1600]{include/natbio-farve}}}

%% Change `ku-en` to `nat-en` to use the `Faculty of Science` header
\AddToShipoutPicture*{\put(0,0){\includegraphics*{include/nat-en}}}

\clearpage\maketitle
\thispagestyle{empty}

\newpage

\abstract

\newpage

\tableofcontents

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%  REPORT STARTS HERE  %%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
In recent years, there has been a lot of focus on leveraging the power of parallel hardware. 
One approach has been to design programming languages with explicit data-parallel constructs that can be compiled 
into highly parallel code. One such language is Futhark. The aim of Futhark is to target parallel hardware such as 
GPUs while itself being the target of more programmer-productivity oriented languages. The Futhark compiler 
performs several optimizations, such as fusion, which enhance the degree of 
parallelism \cite{T.Henriksen&C.Oancea}.\\

APL is an array language and includes various operations that are central to the language and are good candidates 
for parallel execution. Efforts in compiling APL to parallel backends already exist in the form of the language 
TAIL (Typed array intermediate language) and it’s compiler \cite{ElsmanDybdal:Array:2014}.
The TAIL compiler captures the parallelism inherent in APL source code and brings it to a much more manageable form.
In our work we provide a compiler from TAIL 
to Futhark thus bridging the gap between APL and Futhark.\\

The language Futhark is designed to target parallel architectures and at the same time acting 
as an intermediate language for more feature-rich languages. By compiling APL to Futhark through TAIL the 
Futhark compiler can be used to generate parallel code from APL once a parallel backend for 
Futhark is completed.\\

There are traditionally five stages of a compiler if you compile a high level language to machine code: 
lexical analysis, syntax analysis, type checking, intermediate code generation, register allocation, machine 
code generation and assembly and linking \cite{TorbenMogensen}. However, in this project we are compiling from 
one high level language to another high level language. The structure does therefore look a little different. 
The first two phases are still lexical analysis and syntax analysis and are handled by a parser.
We made use of an already existing parser \cite{APLACC} and only modified it in order for it to work on the latest 
version of TAIL. The third phase is transforming the abstract syntax tree of TAIL to the abstract syntax tree 
representing the code in Futhark and the fourth phase is printing the AST so it becomes correct 
Futhark source code. \\

One of the main point of interest in the compilation between TAIL and Futhark is compiling the four array operators 
of TAIL: {\tt each}, {\tt eachV}, 
 {\tt reduce} and {\tt zipWith} to Futhark source code that include the four second-order array combinators in Futhark:  
 {\tt map}, {\tt filter}, {\tt reduce} and {\tt scan} \cite{ElsmanDybdal:Array:2014}\cite{TroelsHenriksen}. 
However as the functionality of these functions are not completely 
identical the work lies in creating a mapping that retains the parallelism in the original code in the target language.\\
This can be seen in the example below which illustrate this difference. The reduce function in the
TAIL language is mapped to a nested reduce function in the Futhark language.
As some function names exists in both languages the Futhark version is \underline{underlined}.

\begin{lstlisting}[numbers=none,frame=none]
$\text{reduce}$(+, [[1,2,3,4],[5,6,7,8]]))

  =>

$\underline{\text{reduce}}$(fn x => map(+,x),[[1,2,3,4],[5,6,7,8,]])

\end{lstlisting}

This paper contributes with a compilation scheme that are implementation independent, showing a replicable 
way of how to translate the typed intermediate language of APL, TAIL, to the functional language Futhark. Also 
this paper presents an implementation of the previous mentioned scheme in Haskell. The efficiency of this
 implementation have been tested by comparing benchmarks test on code generated by the C-backend to TAIL 
 and the generated Futhark source code by using the C-backend to Futhark. \\

The project is open source and the source code can be found here:\\ https://github.com/henrikurms/tail2futhark.

Both Futhark and TAIL are ungoing research projects and are therefore subject to change bear in mind that the references cited are not up to date. For a up to date version of the languages and their compilers refer to their recepctive github repositories: \\

TAIL: https://github.com/melsman/apltail

Futhark: https://github.com/HIPERFIT/futhark

% \section{Outline}
%The compilation scheme presented later in this section is written in a form of short hand notation to be able to have the entire compilation written in a short and very detailed was that is implem

\subsection{Methods and tools}
In this paper a compilation scheme done in a form of mathematical shorthand notation is presented. 
The reason for using this shorthand notation is to be able to express the compilation of the different componants of the compilation seperately and in a very detailed presice manner. 
The notation should also helpget an overview of entire compilation scheme as well as creating a way of talking about a specific component seperatly. The notation is inspired by smiiar notation used in other projects \cite{TorbenMogensen}\cite{MartinElsmanNotation} to describe compilation schemes but is not build on a spefic standard. \\

The scheme gives a conceptual understanding of the compilation that are not muddled up by specific implementation details. The scheme simply illustrates the consepts of the compilation in a very detailed manner while being implementation independent. It therefore a posibility to use the compilation between TAIL and Futhark that is presented in the compilation scheme to create a different implementation than the one presented in this paper.
It also enables us to get an idea of the correctness of the compilation simply by looking at the scheme.????????????????????????????\\

Having the compilation scheme has also made the implementation easier because the functionality and overall idea behind the implementation is done and works as an API. Therefore deviding the implementation between more than one prorammer is fairly easy. \\

To keep the implementation scheme simple we have made a small library of functions ...\\ % explain why this is smart
There is a choice to be made about how to generate and include the library.
We would like the compiler to always output a valid (runnable) Futhark program given a valid TAIL input program, so we would like to
be able to include the library in the output when we run the compiler.
Furthermore since Futhark has no polymorphism we would like to be able to
generate functions with the same implementations but different types from a template.
That way we can be sure the different versions have the same implementation.
Finally since Funthark is eventually expected to feature polymorphism and a module system we would like the solution to not be too
extensive\cite{TroelsHenriksen}. Therefore we have coded the functions in the compiler itself.

The implementation done in this project is written in the functional programming language Haskell. The language constructs in Hasell is very smiliar to the notation and functional languages lend themselves to compilers in general because of the easy case constructs and other constructs... REFERENCE!! \\% hvad ved haskell fik os til at vælge det????

Cabal is used for !!!!!!!!!!!!!!!!!!!!!!\\

The parser we used for this project 


\subsection{Limitations of the compilation}
% it does not work on all tail programs. 
% 

\subsection{Report outline IKKE FAERDIGT!!!}
The follwing sections of the report is structured as follows. Section \ref{sec:tail} and Section \ref{sec:futhark} introduce the source and the target language. Section \ref{sec:scheme} describes the compilation scheme in detail. Secion \ref{sec:impl} is an overview of the implementation.


% into about the skemaet
% Hvorfor valgte vi at lave skemaet
%% det er impl uafhængigt
%% det giver mulighed for at snakke om hver konstruktion enkeltvis
%% giver mulighed for at vise oversættelsen af hver konstruktion enkeltvis
%% giver mulighed for at .. korrektheden af oversættelsen uden at behøve at teste - håndkøre
%% hvad fik vi ud af at lave skemaet. 

% For at holde vores compilation scheme clean har vi valgt at implementere nogle biblioteksfunktioner

% Implementationen er lavet i Haskell da Haskells semantic/syntax er tæt på notationen

% Korektheden af implementationen er testet med et autmated test sweep som kører alle test i en mappe igennem og sammenligner outputtet fra compilationen med outputtet i en specifik output fil der indeholder det forventede resultat.

% Benchmarks...

\section{The intermidiate language TAIL}
\label{sec:tail}

The syntax of the types in TAIL can be seen below. The types are divided into base types ($\kappa$), shape types ($\rho$), types ($\tau$), and type schemes ($\sigma$).The letter $i$ denotes an integer scalar value and the letter $\alpha$, and the letter $\gamma$ denotes type variables and shape variables respectively.
\begin{lstlisting}[numbers=none,frame=none]
$\kappa$ ::= int | double | bool | $\alpha$
$\rho$ ::=  $i$ | $\gamma$ | $\rho$ $+$ $\rho$'
$\tau$ ::= $[\kappa]^{\rho}$ | $\langle \kappa \rangle^\rho$ | S$_{\kappa}$($\rho$) | SV$_{\kappa}$($\rho$) | $\tau \rightarrow \tau$'
$\sigma$ ::= $\forall\overrightarrow{\alpha}\overrightarrow{\gamma}$.$\tau$
\end{lstlisting}
The type system of TAIL supports array types ($[\kappa]^{\rho}$) that keeps track of the shape of an array in its type.
The integer scalar in the arrays shape denotes the rank of the array and must be a non-negative integer.
The type system also supports vector types ($\langle \kappa \rangle^\rho$), this type is used specifically for vectors of a specific length. For example {\tt <int>8} denotes a vector of ints of known length 8. If the vectors length is not staticallly known it can be instead expressed as an array of rank 1.
Scalar values that are statically known have a separate type (S$_{\kappa}$($\rho$)), i.e. integers, doubles, and booleans, their value is contained in the type.
In addition there also exists single-element integer, double, and boolean vector types (SV$_{\kappa}$($\rho$) for arrays where the element is statically known.
Finally there exists function types ($\tau \rightarrow \tau$'). \\

%The types schemes ($\sigma$) are expressed through substitution...
The type system makes use of substitution in order to express type schemes ($\sigma$). Type substitution ($S_t$) that maps type variables to base types and shape substitution ($S_s$) that maps shape variables to shape types. A general substitution ($S$) is a pair ($S_t$,$S_s$) of type substitution and shape substitution. Using the substitution $S$ on an object $B$ means applying 
both $S_t$ and $S_s$ on objects in $B$. A type $\tau$' is an instance of a type scheme $\sigma$ = $\forall\overrightarrow{\alpha}\overrightarrow{\gamma}$.$\tau$ (written $\sigma$= $\tau$') if a substitution $S$ exists such that $S(\tau)$ = $\tau$'. \\

The syntax of operators and expressions is given bellow. The letter $v$ is used to denote values and the letter $x$ is used to denote program variables. 
\begin{lstlisting}[numbers=none,frame=none]
op ::= addi | subi | multi | mini | maxi | addd | subd | 
       muld | mind | maxd | andb | orb | xorb |  nanb | 
       norb | notb | lti | ltei | gti | gtei | eqi | neqi |
       ltd | lted | gtd | gted | eqd | neqd | iota | each |
       reduce | i2d | b2i | reshape0 | reshape | rotate |
       transp | transp2 | zipWith | shape | take | drop |
       first | cat | cons | snoc | shapeV | catV | consV | 
       snocV | iotaV | rotateV | takeV | dropV | firstV 
\end{lstlisting}

\begin{lstlisting}[numbers=none,frame=none]
e ::= $v$ 
    | $x$ 
    | $[\overrightarrow{e}]$ 
    | $e$ $e'$ 
    | let $x$ = $e_1$ in $e_2$ 
    | $op(\overrightarrow{e})$
\end{lstlisting}
A TAIL program always consists of a single expression. An expression can then be a value, variable, 
list of expressions, a let expression or an operator. Each TAIL operator has a unique type scheme. \\

One of the operators with a simple type scheme is the binary operator maxi that take two arguments $a$ and $b$ evaluates to the argument with the highest value. Its type scheme are as follows:
\begin{lstlisting}[numbers=none,frame=none]
maxi : int $\rightarrow$ int $\rightarrow$ int
\end{lstlisting}

Other operators have more complex type schemes. Examples of those are the parallel operators. 
There are four parallel operators in TAIL, {\tt each}, {\tt eachV}, {\tt reduce} and {\tt zipWith}.
The functions {\tt each} and {\tt eachV} are known in many languages as map.
The type scheme for the function {\tt each} is:
\begin{lstlisting}[numbers=none,frame=none]
each : $\forall\alpha\beta\gamma.(\alpha \rightarrow \beta)\rightarrow [\alpha]^{\gamma} \rightarrow [\beta]^{\gamma}$
\end{lstlisting}
Given a function $f$ and an array $a$ {\tt each f a } evaluates to an array where $f$ is applied to each element of $a$ i.e. $[f(a_1),..,f(a_n)]$.
If the rank of the array is greater than 1 the {\tt each} function works as a map on the fattened representation of the array,
that is, the function is applied on the inner most dimension of the array, or seen in another way, on each basic value.

The {\tt eachV} function is a special case of {\tt each} and is used on vector types.\\

The function {\tt reduce} works similar to fold known from functional languages. The type scheme for {\tt reduce} is:
\begin{lstlisting}[numbers=none,frame=none]
reduce : $\forall\alpha\gamma.(\alpha \rightarrow \alpha \rightarrow \alpha)\rightarrow \alpha \rightarrow [\alpha]^{1 +\gamma} \rightarrow [\alpha]^{\gamma}$
\end{lstlisting}
The function takes as arguments a associative binary operator $op$ (for instance $+$), a neutral element $n$, (for instance 0) and array $a$.
The function application evaluates to the combination of the elements by the operator.
An array of rank $\gamma+1$ is reduced to an array of rank $\gamma$ along the inner-most dimension.
Unlike {\tt fold}, reduce makes no guarantees as to the order of application of the operator, therefore the operator has to be associative and the element has to be neutral, this is of course necessary for parallel execution.\\

The {\tt zipWith} function's type scheme is given as follows: 
\begin{lstlisting}[numbers=none,frame=none]
zipWith  : $\forall\alpha_{1}\alpha_{2}\beta\gamma.(\alpha_1 \rightarrow \alpha_2 \rightarrow \beta)\rightarrow [\alpha_1]^{\gamma} \rightarrow [\alpha_2]^{\gamma} \rightarrow [\beta]^{\gamma}$
\end{lstlisting}
Given a function $f$ that works on a pair $(x,y)$ and two arrays $a_1$ and $a_2$, {\tt zipWith f a\_1 a\_2}  evaluates to an array where the n'th element is $f$ applied to the pair $({a_{1}}_n,{a_{2}}_n)$ 
Like the other three operators it works on the inner-most dimension of the array\cite{ElsmanDybdal:Array:2014}.\\

There are other interesting operators besides the parallel ones. One of them is the operator {\tt reshape($a_1$,$a_2$)}.
Given two arrays it reshapes the flattened representation of the second array $a_2$ to the dimensions given by the first array so 
if we have $reshape([2,3],[1,2,3,4,5,6])$ it evaluates to $[[1,2,3],[4,5,6]]$.
If $a_2$ is to long the elements not needed are dropped i.e. $reshape([2,3],[1,2,3,4,5,6,7,8])$ would evaluate to the same as the first example.
If $a_2$ is sorter than needed the elements of $a_2$ are repeated, for instance $reshape([2,3],[1,2,3])$ evaluates to $[[1,2,3],[1,2,3]]$.\\

Other interesting operators are {\tt take($i$,$a$)} and {\tt drop($i$,$a$)}.
They return an array containing the 1st to $i$'th element of $a$,
and the array containing the $i$'th to n'th element of $a$ respectively.
If the array is multi-dimensional the operator works on the outermost dimesion of the array i.e.
$take(2,[[1,2],[3,4][5,6]])$ evaluates to $[[1,2],[3,4]]$.
If the array contains to few elements {\tt take} pads the array with zeros,
whereas {\tt drop} returns the empty array in case one tries to drop more elements than there are in $a$. \\

The operator {\tt snoc(a,e)} takes two arrays $a$ and $e$ and return an array where the i'th element of $e$ is appended onto the end of the i'th row of $a$.
If there is too few elements in $e$ you get an error,
except if there is only one element in $e$ then the operator evaluates to an array where the one element from $e$
is appended onto each row of $a$.\\

The operator {\tt cons(e,a)} has very similar semantics as the {\tt snoc} operator.
The only difference is that it appends the contents of $e$ not on the end but at the beginning of each row.\\

The operator {\tt cat($a_1$,$a_2$)} takes two arrays that have to have the same outer dimension and returns an array where the i'th element (for instance row if the array is two-dimensional) of $a_2$ is appended onto the end of the i'th element of $a_1$.\\

The {\tt transp} operator takes an array and return the transposed array i.e.\\
 $transp([[1,2,3],[4,5,6]])$ would return $[[1,4],[2,5],[3,6]]$. If the array is multi-dimensional for instance a three-dimensional array with the shape $2x3x4$ the function would return an array with the shape $4x3x2$.\\

The background for designing TAIL was to create a typed intermediate language for the array programming language APL.
TAIL is still under development and so is the {\tt apltail} compiler which compiles a subset of APL into
TAIL \cite{ElsmanDybdal:Array:2014}.
APL is an older language created in the 1960's by Kenneth E. Iverson.
APL is an array programming language, its main type is the multi-dimensional array 
and most of the built-in functions in the language are array operators that work on this type. 
Most of its built-in functions or operators are represented by unicode symbols allowing for very concise code.
The APL language is dynamically typed. It supports first and second order functions and these functions work on arrays of any type. 
Even though it is an old language it is still used in the financial world 
where large code bases are still operational and actively developed \cite{ElsmanDybdal:Array:2014}. \\

TAIL was designed with the purpose of targeting parallel architectures such as GPUs and allows parallel programs to be
expressed in a highly abstract manner.
The TAIL compiler can also efficiently compile TAIL code into sequential code in a C-like language.
The subset of APL operators that TAIL support are shown earlier in this section.

The TAIL compiler infers types for the values in the APL program and can annotate bindings with
instance declarations. An instance declaration provides the base type and rank of the array. Or in
the case of vectors the size of the vector.

The language TAIL is statically typed and supports polymorphism. 
Most of the operators in TAIL are very general i.e. they are polymorphic with respect to array ranks and base types.
Although for some operations a specific type is needed.
An example is the {\tt take} function. It takes as argument a number (of type int) and an array of type $\alpha^\gamma$.\\

 TAILs type system takes the dynamically types of APL and transforms it to a more manageable form adding explicit type
 information to the constructs.
Another benefit of the expressiveness of TAILs type system is that it allows the (TAIL) compiler to express some operators which
are primitive in APL using simpler operators, one such operator is that of the inner product \cite{ElsmanDybdal:Array:2014}. \\

The aplacc parser for TAIL represents the TAIL expressions in the abstract syntax tree as variables, constants, infinity, the negative representation of 
the expression, let expressions, operators and lambda expressions. 

% THIS IS HOW THE COMPILER IMPLEMENTS EXPRESSIONS
%\begin{lstlisting}[numbers=none,frame=none]
%e ::= x | i | d | c | inf | -e | let x:$t$ = e$_1$ in e$_2$ |
%      op[e$_1$,...,e$_n$] | fn x:$t$ e | [e$_1$,...,e$_n$]
%\end{lstlisting}

TAIL does not support curried functions but require functions to be fully applied.

% In APL indexing are done with 1-indexing but it is possible to change the indexing to 0-indexing on the fly. 

%So far TAIL only support a subset of the APL functions and operators. 

\section{The functional language Futhark}
\label{sec:futhark}

In this section we give a short introduction to the Futhark language, we will only cover the parts that are necessary to understand
the reasoning behind our compilation approach. For the full language reference please refer to (ref).

The syntax of Futhark types can be seen below.
\begin{lstlisting}[numbers=none,frame=none]
$t$   $::=$   int          (Integers)
    | real         (Float)
    | bool         (Booleans)
    | char         (Characters)
    | {$t_1$,...,$t_n$}      (Tuples)
    | [t]          (Arrays)
    | *[t]         (Unique arrays)
\end{lstlisting}
The types in Futhark consist of four base types: integers, floating points, booleans, tuples ({\tt \{t$_1$,...,t$_n$\}}), arrays ({\tt [t]}), and unique arrays ({\tt *[t]}).
Tuple types are written as a comma separated list of types or values surrounded by braces. For example {\tt\{int,bool\}} is 
a pair of values of integer and boolean types.
Unlike TAIL, Futhark allows nesting of arrays and indeed nested arrays are how multi-dimensional arrays are expressed in Futhark.
Array types are denoted by the elements (base) type enclosed by brackets.
The layer of brackets indicates the dimensionality of the array type.
For instance {\tt [int]} is a one-dimensional array of integers, and {\tt [[[bool]]]} is a tree-dimensional array of booleans.
Arrays must be regular, i.e. all arrays in an array must have the same number of elements. \\

The Futhark language is statically typed but does not use type interference. Also the type system of Futhark is not 
able to express polymorphism, this means it is not possible to make polymorphic functions in Futhark.
The only exception is that a lot of the built-in functions can be used on multiple types.\\

The syntax of Futhark expressions is show below as follows:
\begin{lstlisting}[numbers=none,frame=none]
$k$ ::= $n$ | $x$ | $b$ | $c$ | {$v_1$,...,$v_n$} | [v$_1$,...,$v_n$] 
\end{lstlisting}
\begin{lstlisting}[numbers=none,frame=none]
$p$ ::= $id$ | {$p_1$,...,$p_n$}
\end{lstlisting}

\begin{lstlisting}[numbers=none,frame=none]
$e$ ::=  $k$
    | $v$ 
    | {$e_1,...,e_n$} 
    | [$e_1,...,e_n$] 
    | $e_1$ $\odot$ $e_2$ 
    | $-e$ 
    | !$e$ 
    | if $e_1$ then $e_2$ else $e_3$ 
    | $v$[$e_1,...,e_n$] 
    | $v$($e_1,...,e_n$) 
    | let $p$ = $e_1$ in $e_2$
    | zip($e_1,...,e_n$) 
    | unzip($e$)
    | iota($e$) 
    | replicate($e_n, e_v$) 
    | size($i$,$e$) 
    | reshape(($e_1,...,e_n$),e)
    | transpose($e$)
    | split($e_1,e_2$)
    | concat($e_1,e_2$)
    | let $v_1$ = $v_2$ with [$e_1,...,e_n$] <- $e_v$ in $e_b$
    | loop ($p$ = $e_1$) = for $v$ < $e_2$ do $e_3$ in $e_4$
    | map($l$, $e$)
    | filter($l$, $e$)
    | reduce($l$, $x$, $e$)
    | scan($l$, $x$, $e$)
\end{lstlisting}

\begin{lstlisting}[numbers=none,frame=none]
$l$ ::=  fn $t$ ($t_1$ $v_1,..., t_n$ $v_n$) => $e$
    | $id$ ($e_1,...,e_n$)
    | op $\odot$ ($e_1,..., e_n$)
\end{lstlisting}

\begin{lstlisting}[numbers=none,frame=none]
$fun$ ::=  fun t v(t$_1$ v$_1$,...t$_n$ v$_n$) = $e$
\end{lstlisting}

\begin{lstlisting}[numbers=none,frame=none]
$prog$ ::= $\epsilon$ | $fun$ $prog$
\end{lstlisting}

Note that the syntactical construct denoted by $l$ can only occur in {\tt map}, {\tt filter}, {\tt reduce} and {\tt scan}.
The functions {\tt map }, {\tt filter }, {\tt reduce } and {\tt scan } are second-order array combinators, or SOACs for short.

The SOACs operate on arrays with first-order functions given as arguments.
Functional arguments used can be function names of first-order functions (either user-defined or built-in), 
binary operators, or lambda expressions.
Futhermore in a SOAC expression operators and functions can be curried. Lambda expressions require explicit type annotations for
the return type and argument types, and argument bindings follow the normal shadowing rules.

We do not target the SOACs {\tt filter} and {\tt scan} in our compilation, and as such will not discuss them here.
The SOACs can be used on arrays of any type even though it cannot be expressed by Futhark types, for clarity we give the type for each SOAC that it would have had in a polymorphic language.
Below we shortly discuss {\tt map} and {\tt reduce}.

The function {\tt map} has the following type: 
\begin{lstlisting}[numbers=none,frame=none]
map : ($\alpha$ $\rightarrow$ $\beta$) $\rightarrow$ $[\alpha]$ $\rightarrow$ $[\beta]$
\end{lstlisting}
The function {\tt map($l$,$a$)} takes a function $l$ and an array $a$ and evaluates to the array consisting of $l$ applied to each element of $a$.
In contrast to TAIL, if the array is multi-dimensional the function is applied to the outer most dimension.
This means that if the function $l$ is mapped into a 2-dimensional array the function would be applied to an array not the elements
of the array. This makes sense considering that Futhark represents multi-dimensional arrays using nested arrays.\\

The type of the function {\tt reduce} is: 
\begin{lstlisting}[numbers=none,frame=none]
reduce : ($\alpha$ $\rightarrow$ $\alpha$ $\rightarrow$ $\alpha$) $\rightarrow$ $\alpha$ $\rightarrow$ $[\alpha]$ $\rightarrow$ $\alpha$
\end{lstlisting}
Given a binary operator/function $l$, the neutral element $e$ of $l$ and an array $a$,
{\tt reduce } evaluates to the result of applying $l$ to combine all the elements of $a$, i.e. 
\begin{lstlisting}[numbers=none,frame=none]
$e \odot a[0] \odot \ldots \odot a[n]$ where $x \odot y = l (x,y)$
\end{lstlisting}
Like {\tt map}, {\tt reduce} applies the function on the outer-most dimension of the array. \cite{TroelsHenriksen}.\\ 

The first-order segment of Futhark has many of the typical language features like constants, variables, many of the usual binary operators, branching, array indexing and some additional features like in-place updates and looping which we do not use.

Futhark features array zipping with the built-in {\tt zip} which produces an array of pairs from a pair of arrays.
The resulting arrays can then be mapped over with binary operators such as +.\\

The {\tt iota} function given an integer $n$ produces an array with integer values ranging from 0 to $n-1$.
The {\tt replicate} function given an integer $n$ and an array $a$ returns an array consisting of $n$ copies of $a$.
The {\tt size} primitive will given a positive integer $i$ and an array $a$ return the i'th dimension, or put in another way
the length of the arrays nested with depth $i$ in $a$. Remember that these arrays will all have the same length.
The {\tt reshape} function takes a number of dimensions $(dim_1,..., dim_n)$ and an array $a$ and returns an array where the elements of $a$ is reshaped into the shape specified by the list of dimensions.
The number of elements in $a$ must be equal to the product of the dimensions i.e. $elements$ $of$ $a$ $=$ $dim_1 * ... * dim_n$.\\

The function {\tt transpose} take an array $a$ and return the transposed $a$.
If {\tt transpose} is used on an array of more than two dimensions it transposes the array a little different than one might expect.
For instance the result of transposing an three-dimensional array with dimensions $2 x 3 x 4$ is not as one might expect an array with dimensions $4 x 3x 2$ but instead an array with dimensions $3x4x2$.\\

The function {\tt split} given an integer $n$ and an array $a$ partitions $a$ into two arrays $a[0,..,n]$ and $a[n+1,...]$ and returns them as a tuple. 
The function {\tt concat} takes two arrays and concatenates them by concatenating the row/elements of one array with another. The shape of the two arrays have to be the same except in the first dimension. 

The undocumented {\tt rearrange} function takes as arguments a comma separated list of dimensions (surrounded in parentheses) and an array. It then rearranges the shape of the array to the by the list specified. \\

The aim of Futhark is to be an attractive choice for expressing complex parallel programs.
This goal is pursued by featuring high expressive power without
losing the ability to do aggressive optimization and managing parallelism.
This is a challenge because higher expressive power means optimizations become more difficult. 
However Futhark does support nested parallelism as this is a feature many programs 
depend upon even though it does make optimization more difficult \cite{TroelsHenriksen}.

% funktioner bliver inlinet

% funktioner skla definere returtype og type på alle argumenter

%Does not support polymorfism in types

\section{The compilation strategy}
Where possible, TAIL privimitives have mapped directly to their corresponding versions in the Futhark language.
Where direct translation is not possible the approach has been to ?? and generate code to bridge the gap.

%map -> map
% use map
% don't use loops
% no optimizations (rely of futhark optmizations)
% library functions to simplify compilation

%The first case is for example seen in the compilation of let-expressions and many of the basic scalar operators (e.g. plus).
%The second case is seen in for example the compilation of the iota operator.

The general strategy for compiling TAIL expressions
was to use as many of the built-in functions in Futhark to express them as possible
and then rely on Futharks havy optimization on its built-in functions to remove any overhead that the compilation from TAIL to Futhark could have created
as focusing on optimizing the code was not part of this project. \\
 %(et eller andet med det overhead eller sådan noget som vi potentielt kan have skabt kva at vi stort set ikke har tænkt på hvad der er optimalt.)

In the cases where it was not posible to use built-in Futhark functions library functions was created instead. 
%There are several reasons for making libary functions. One was to keep our compilation scheme simple.
%By having a small library of Furhark functions which is inlined in each compiled program we... % ja hvad får vi egentlig ud af det??? :)

Many of the monomorphic first-order functions of TAIL are mapped directly to a library function of the same name. This also allows us to use the same mapping when the functions occur as arguments in SOAC applications.\\

% Er der flere fordele ved biblioteksfunktionerne??
% Hvad er det negative ved biblioteksfuntionerne
% Hvad var alternativet 

\section{Library functions}
In this section we go over some of the library functions we have defined and discuss their usefulness.\\

The {\tt take1}, {\tt drop1} and {\tt reshape1} functions implement the TAIL operators {\tt take}, {\tt drop} and {\tt reshape} in the one-dimensional case. In Section \ref{sec:scheme}, we see how they can be used to implement the multi-dimensional cases. It is advantageous to use a library function for only the one-dimensional case as we would otherwise need a separate library function for each 
rank and basic type combination which we then needed to call since Futhark only allows declaration of monomorphic functions \cite{TroelsHenriksen}.
There is a template for each of the functions that make four functions (one for each base type). This way we can be sure to have the same function code for each type and it makes maintaning the functions easier. 

\paragraph{The take1 functions} is defined as follow. Note that this int version.
\begin{lstlisting}[language=Futhark]
fun [int] take1_int(int l,[int] x) =
  if (0 <= l)
  then if (l <= size(0,x))
       then let {v1,_} = split((l),x) in v1
       else concat(x,replicate((l - size(0,x)),0))
  else if (0 <= (l + size(0,x)))
       then let {_,v2} = split(((l + size(0,x))),x) in v2
       else concat(replicate((l - size(0,x)),0),x)
\end{lstlisting}

The function first checks if it should perform a positive of negative take and then checks whether it should split so it can return
part of the argument or pad the argument with zeros based on whether the take size was smaller or bigger than the array.

%TODO what details are we missing?
%TODO discuss how it knows what to pad with
\paragraph{The drop1 functions}

\begin{lstlisting}[language=Futhark]
fun [int] drop1_int(int l,[int] x) =
  if (size(0,x) <= if (l <= 0) then -l else l)
  then empty(int)
  else if (l <= 0)
       then let {v1,_} = split(((l + size(0,x))),x) in v1
       else let {_,v2} = split((l),x) in v2
\end{lstlisting}

\paragraph{The reshape functions} int version can be seen below. 

To adjust the array we first make sure it is long enough by extending it using the function replicate and then
truncate it to the correct length with split.

\begin{lstlisting}[language=Futhark]
fun [int] reshape1_int(int l,[int] x) =
  let roundUp = ((l + (size(0,x) - 1)) / size(0,x)) in
  let extend = reshape(((size(0,x) * roundUp)),replicate(roundUp,x)) in
  let {v1,_} = split((l),extend) in v1
\end{lstlisting}

When we replicate an array in Futhark the rank of the array increases by one so we have to reshape the array back to rank 1 before
we split it. To number of times we should replicate the array is the target size divided by the array size rounded up.
This is computed in the variable roundUp, we add denominator plus one to the enumerator to round up as normal integer division
round down.

%Nevertheless we inline the flattening and reshaping code so we only need reshape functions written in Futhark
%for the one dimensional cases. If we wanted to simply call a function instead we would need a separate library function for each
%rank and basic type combination which we needed to call reshape on since Futhark only allows declaration of monomorphic functions \cite{TroelsHenriksen}.

\paragraph{Bool equality}

Futhark has no bool equality so we implemented our own:

\begin{lstlisting}[language=Futhark]
fun bool eqb(bool x,bool y) =
  (!((x || y)) || (x && y))
\end{lstlisting}

Two booleans are equal if they both are true or none of them are true.
\paragraph{Xor} Likewise there is no logical xor operation so we included it in the library:

\begin{lstlisting}[language=Futhark]
fun bool xorb(bool x,bool y) =
  (!((x && y)) && (x || y))
\end{lstlisting}

The Xor of two booleans is true if one but not both of them are true.
\\

There are more than the above mentioned but these are implemented very straight forward and are therefore only mentioned here: \\

Liste af resten af biblioteksfunktionerne

% definition of each of the library functions

\section{The compilation scheme}
\label{sec:scheme}
There main contribution with this paper is the compilation scheme presented in this section. It shows in details a possible  compilation of a subset of TAIL's operators to Futhark source code. The compilation scheme is done in a short hand notation to enable easy redability while still contaning a very high level of detail. The general strategy behind the compilation is explained in this section and a walk through of the compilation of some of the more interesting operators or expressions of TAIL is described in detail. \\

% Presentation of the compilation scheme
% Explain the reson for making the scheme
%% Implementation independent overview of the compilation
%% A way to easy create an overview thereby limiting the chances that we missed something
%% Easy for others to use 
%% way to get the ide down on paper
% Explain the notation/ who to read the scheme
%% how is it possible to destinct between futhark and tail functions/expressions 
%% how is the types represented og hvad betydning har de
% Explain the general idea behind the compilation
%% try to use futhark functions whenever posible.
%% inlined library functions to deal with cases where no futhark function existed or polymorphism was required
%%% explain WHY we chose libraryfunctions and what the alternative was. 
% Walkthrough of some of the more interesting compilations. Explain WHY we did what we did. 
\newgeometry{top=15pt,left=30pt}
\begin{flushleft}
\begin{tabular}{@{}l c l}% to \linewidth {l c X}
$\evals{x}$ & $=$ & $x$ \\
$\evals{i}$ & $=$ & $i$ \\
$\evals{d}$ & $=$ & $d$ \\
$\evals{c}$ & $=$ & $c$ \\
$\evals{-e}$ & $=$ & -$\evals{e}$ \\
$\evals{ \text{let } x:t = e_1 \text{ in } e_2} $ & $=$ & let $\evals{x} = \evals{e_1} \text{ in } \evals{e_2} $\\
$\evals{[e_1,...,e_n]}$ & $=$ & $ [ \evals{e_1},...,\evals{e_n}]$\\

$\evals{\text{op} [e_1,e_2]}$ & $=$ & $\evals{e_1} \; \evals{\text{op}}_{op} \; \evals{e_2}$, $$op $ \in binops$\\
$\evals{\text{op} [e_1,...,e_n]}$ & $=$ & $\evals{\text{op}}_{fun} \; (\evals{e_1},...,\evals{e_n})$, $$op $ \in funs$\\

$\evals{\text{each}_{[t_1,t_2,r]}(f,a)}$ & $=$ & $
  \begin{cases}
    $map$(\evals{f}_{fn}^{\evals{t_2}},\evals{a}) & r=1\\
    $map (fn $t_2^r \; (t_1^r \; x)$ {\tt =>} $ \evals{\text{each}_{[t,r-1]}(f,x)},\evals{a}) & r > 1  \\
  \end{cases}$\\

$\evals{\text{eachV}_{[t_1,t_2,r]}(f,a)}$ & $=$ & map$(\evals{f}_{fn}^{\evals{t_2}},\evals{a}) $  \\      

$\evals{\text{reduce}_{[t,r]}(f,n,a)}$ & $=$ & $
  \begin{cases}
    \text{reduce}(\evals{f}_{fn}^{\evals{t}},\evals{n},\evals{a}) & r=1 \\
    $map (fn $ t^{r-1} \; (t^r \; x)$ {\tt =>} $ \evals{\text{reduce}_{[t,r-1]}(f,n,x)},\evals{a}) & r>1\\
  \end{cases}$\\   

$\evals{\text{zipWith}_{[t_1,t_2,t_3,r]}(f,a_1,a_2)}$ & $=$ & \\
  \multicolumn{3}{r}{ $\begin{cases}
    $map$(\evals{f}_{fn}^{\evals{t_3}},$zip($\evals{a_1},\evals{a_2})) & r=1 \\
    $map(fn $t_3^{r-1} \; (t_1^{r-1} \; x, t_2^{r-1} \; y) $ {\tt =>} $
      \evals{\text{zipWith}_{[t_1,t_2,t_3r-1]}(f,x,y)} , $zip($ \evals{a_1}, \evals{a_2})) & r>1\\
  \end{cases}$ }\\
  
$\evals{\text{vrotate}_{[t,r]}(i,a)}$ & $=$ & map(fn x {\tt =>} a[x + i {\tt \%} \text{size}(0,a)], iota(size(0,a)) \space\space , x = fresh\\

$\evals{\text{vreverse}_{[t,r]}(a)}$ & $=$ & map(fn x {\tt =>} a[\text{size}(0,a)-x-1], $\text{iota}(\text{size}(0,a))$ \space\space , x = fresh\\

$\evals{\text{reshape}_{[t,r_1,r]}(a_1,a_2)}$ & $=$ & reshape$(\evals{a_1},(\text{reshape1}_{\evals{t}}(
\text{osize}
, \text{reshape}(
\text{isize}
, \evals{a_2})))) $ \\
&& \hspace{4ex} where osize = $\text{size}(0,a_1)*\ldots*\text{size}(r_1,a_1)$ \\
&& \hspace{4ex} \phantom{where} isize = $ \text{size}(0,a_2)*\ldots*\text{size}(r_2,a_2) $ \\

$\evals{\text{cat}_{[t,r]}(a_1,a_2)}$ & $=$ & $
  \begin{cases}
    \text{concat}(\evals{a_1},\evals{a_2}) & r=1 \\
    $map (fn $ \evals{t}^{r-1} \; (\evals{t} \; x, \evals{t} \; y)$ {\tt =>} $ \evals{\text{cat}_{[t,r-1]}(x,y)}, \text{zip}(\evals{a_1}, \evals{a_2}) & r>1\\
  \end{cases}$\\

$\evals{\text{first}_{[t,r]}(a)}$ & $=$ & let x = $\evals{a}$ in $x[\underbrace{0,...,0}_\text{r times}]$\\

$\evals{\text{firstV}_{[t,r]}(a)}$ & $=$ & $\evals{\text{first}_{t,1}(a)}$\\

$\evals{\text{take}(i,a)}$ & $=$ & reshape(oshape,\text{take1}$_{\evals{t}}$(osize,\text{reshape}(isize,$\evals{a})))$\\
&& \hspace{4ex} where oshape = ($|i|, \text{size}(1,\evals{a}),\cdots,$size(r,$\evals{a}$))\\
&& \hspace{4ex} \phantom{where} osize = ($i* \text{size}(1,\evals{a}) *\ldots*$size(r,$\evals{a}$))\\
&& \hspace{4ex} \phantom{where} isize = \text{size}(0,$\evals{a}$)$*\ldots*$\text{size}(r,$\evals{a}$)\\

$\evals{\text{takeV}_t(d,a)}$ & $=$ & $\text{take1}_{\evals{t}}(\evals{d},\evals{a})$\\

$\evals{\text{drop}(i,a)}$ & $=$ & \text{reshape}(\text{oshape}, $\text{drop1}_{\evals{t}}(\text{osize}, \text{reshape}(\text{isize},\evals{a}))$\\
&& \hspace{4ex} where oshape = (max(0,size(0,$\evals{a}$)-$|i|$),size(1,$\evals{a}$)$,\ldots,$size(r,$\evals{a}$))\\
&& \hspace{4ex} \phantom{where} osize = ($i *$size(1,$\evals{a}$)$ * \ldots*$size(r, $\evals{a}$))\\
&& \hspace{4ex} \phantom{where} isize = \text{size}(0,$\evals{a}$)$*\ldots*$\text{size}(r,$\evals{a}$)\\

$\evals{\text{dropV}_t(d,a)}$ & $=$ & $\text{drop1}_{\evals{t}}(\evals{d},\evals{a})$\\

$\evals{\text{transp}_{t,r}(a)}$ & $=$ & rearrange$((r-1,...,0),\evals{a})$\\

$\evals{\text{transp2}_{t,r}(a_1,a_2)}$ & $=$ & let $x$ = $\evals{a_1}$ in rearrange(($x[0]$-$1,\ldots,x[r$-$1]$-$1$),$\evals{a_2})$\\

$\evals{\text{cons}_[t,r](e,a)}$ & $=$ & rearrange$((r,\ldots,0), \text{concat(exp,arr)})$\\
&& \hspace{4ex} where exp = rearrange((r-1,\ldots,0),$\evals{e}$)\\
&& \hspace{4ex} \phantom{where} arr = rearrange((r-1,\ldots,0),$\evals{a}$)\\
  
$\evals{\text{snoc}_[t,r](a,e)}$ & $=$ & rearrange$((r,\ldots,0), \text{concat(arr,exp)})$\\
&& \hspace{4ex} where exp = rearrange((r-1,\ldots,0),$\evals{e}$)\\
&& \hspace{4ex} \phantom{where} arr = rearrange((r-1,\ldots,0),$\evals{a}$)\\

$\evals{\text{iota}(a)}$ & $=$ & map$(+ \; (1), \text{iota}(\evals{a})$\\

$\evals{\text{iotaV}(a)}$ & $=$ & $\evals{\text{iota}(a)}$\\

$\evals{\text{shape}_{t,r}(a)}$ & $=$ & $[\text{size}(0,\evals{a}),...,\text{size}(r-1,\evals{a})]$\\

$\evals{\text{shapeV}_{t,r}(a)}$ & $=$ & $[r]$\\
\\
$\evals{ \text{fn } x:t $ {\tt =>} $ e}^{\tau}_{fn} $ & $=$ & $ \text{fn } \tau (\evals{t}\; x) $ {\tt =>} $ \evals{e}$\\
$\evals{ \text{fn } x:t_1$ {\tt =>} $\text{fn } y:t_2 $ {\tt =>} $ e}^{\tau}_{fn} $ & $=$ & $ \text{fn } \tau (\evals{t_1}\; x, \evals{t_2} \; y) $ {\tt =>} $ \evals{e}$\\
$\evals{\text{op}}^{\tau}_{fn}$ & = & $ \begin{cases} \evals{\text{op}}_{fun} & op \in funs \\ \evals{\text{op}}_{op} & op \in binops \end{cases}$
\end{tabular}
\begin{tabu} to \linewidth { l X}
$binops$ =& addi, subi, muli, ...\\
$funs$ =& i2d, catV, b2i, b2iV, ln, exod, notb, negi, negd, absi, absd, mini, mind, signd, signi, maxi, maxd, eqb, xorb,
nandb, norb, neqi, neqd
\end{tabu}
\end{flushleft}
\restoregeometry
\subsection{The notation}
To denote the compilation of an TAIL expression is a pair of double brackets $\evals{ \; }$. 
In the compilation scheme all the expressions written on the left hand side of the scheme (to the left of the equel sign) is the TAIL expressions to be compiled, the right hand side contains the Futhark functions or expressions they are translated to. An exception to this is expressions that is wrapped in double brackets.
An expression wrapped in double brackets e.g. $\evals{x}$ signifies the compilation of the TAIL expression $x$ no matter what side of the equal sign it is on.\\

Some TAIL expressions have type information as part of their declaration. This type information can be seen in the
compilation scheme as subscript to the function. The type information can be either just a type $t$ or a combination of both type and rank $r$. The type consist of a type that are one of the TAIL
types described in Section 2. The rank is the number of dimensions.  \\

Type information can also be represented by $\tau$, but only in the special case of anonymus functions (fn) where it 
indicate the return type of the anonymus function. This types is not an apparent part of the anonymus function in TAIL
but the type information exist as part of the function that calls the internal function. For instance if the TAIL operator {\tt each(f,a)} is given a kernel (fn) expression as it function f the return type of the kernel can be made from the returntype of the {\tt each} operator that we know at compile time. The return type of the operator that calls the kernel is therefore pased to the kernel for it to create its return type. \\

In the compilation scheme the compilation declarations can be one of three different types. The three types can be destingused by the subtext following the declaration.  Expressions have no subtext, operators are indicated with the subtext $_{op}$ or $_{fun}$ depending on the number of arguments, and kernels are specified with the subtext $_{fn}$. The reason for the distinction is that a TAIL operator can be expressed as either a Futhark binary operator if the expression only takes two arguments and are one of the known operators that can be found in the $binops$ set or a Futhark function. \\



mappings of functions here!! (and list identitiy mappings)\\
\begin{tabular}{l c l}
$\evals{i2d}_{fun}$ & $=$ & toReal\\ 
\end{tabular}\\

\subsection{Walk through of the compilation}

% MÅSKE LYDER DET HER BEDRE?
%
%In this section we are going to introduce our compilation scheme and explain the problems in compiling the different functions
%having a special focus on the more interesting cases.
%We will also explain our reasoning behind the chosen compilation and what alternatives there are.

Several of the TAIL operators and expressions have details in their compilation that is woth looking into to understand the compilation in more details. That means the parallel operators {\tt each} and {\tt reduce} but also let-expressions and lambda expressions to mention a few. For completeness some of the operators that have more obvius compilations are also described. 

\paragraph{Binaryscalar first-order  operators} are mapped to their natural Futhark counterparts, we include the mappings
here for completeness.

mappings of operators here!

\begin{tabular}{l c l}
$\evals{$addi$}_{op}$ & $=$ & $+$\\
$\evals{$addd$}_{op}$ & $=$ & $+$\\
$\evals{$subi$}_{op}$ & $=$ & $-$\\
$\evals{$subd$}_{op}$ & $=$ & $-$\\
$\evals{$multi$}_{op}$ & $=$ & $*$\\
$\evals{$multd$}_{op}$ & $=$ & $*$\\
$\evals{$ltei$}_{op}$ & $=$ & $\leq$\\
$\evals{$lted$}_{op}$ & $=$ & $\leq$\\
$\evals{$eqi$}_{op}$ & $=$ & $==$\\
$\evals{$eqd$}_{op}$ & $=$ & $==$\\
$\evals{$gti$}_{op}$ & $=$ & $>$\\
$\evals{$gtd$}_{op}$ & $=$ & $>$\\
$\evals{$gtei$}_{op}$ & $=$ & $\geq$\\
$\evals{$gted$}_{op}$ & $=$ & $\geq$\\
$\evals{$andb$}_{op}$ & $=$ & $\&\&$\\
$\evals{$orb$}_{op}$ & $=$ & $||$\\
$\evals{$divi$}_{op}$ & $=$ & $/$\\
$\evals{$divd$}_{op}$ & $=$ & $/$\\
$\evals{$powi$}_{op}$ & $=$ & $pow$\\
$\evals{$powd$}_{op}$ & $=$ & $pow$\\
$\evals{$lti$}_{op}$ & $=$ & $<$\\
$\evals{$ltd$}_{op}$ & $=$ & $<$\\
$\evals{$andi$}_{op}$ & $=$ & $\&$\\
$\evals{$andd$}_{op}$ & $=$ & $\&$\\
$\evals{$ori$}_{op}$ & $=$ & $|$\\
$\evals{$shli$}_{op}$ & $=$ & $<<$\\
$\evals{$shri$}_{op}$ & $=$ & $>>$\\

\end{tabular}\\
  

The compilation of the TAIL operators that are not binary operators are explained in details below:\\

\paragraph{Basic structural constructs} are translated to their Futhark counterparts directly.
In let-expresions the type annotations that exist in TAIL variable bindings are ignored in Futhark. 
% var, literals/constants, let, array litterals, neg

The letters $x$, $i$, $d$, and $c$ denote variables, integers, doubles, booleans and chars respectively.
They are all translated to their Futhark equivalents.\\

\paragraph{The each operator} 
 
The {\tt each} operato in TAIL applies a function to every element in the flat representation of the array.
This is a completely parallel operation more commonly known as map.
The {\tt map} combinator in Futhark has slightly different semantics\cite{ElsmanDybdal:Array:2014}.
Since Futhark views a multidimensional array as nested simple arrays it applies the function to every array element.
That is, it maps the function into the outer-most dimension of the array\cite{TroelsHenriksen}.
 
To solve this problem we have nested {\tt map}s to the depth of the array with the required function,
for example, an {\tt each} operation over an array of rank 2 would have two {\tt map}s nested in each other so the kernel is
mapped on each element of basic type.
 
For example an each operation on an array of rank 2 will look like:
\begin{lstlisting}[numbers=none,frame=none]
each(f,a)       =>      map(fn x => map (f,x), a)
\end{lstlisting}


\paragraph{The reduce operator} 
The type of the {\tt reduce} function is $reduce(f,id,a) :: \forall\alpha\gamma.(\alpha \to \alpha \to \alpha) \to \alpha \to [\alpha]^{\gamma+1} \to [\alpha]^\gamma$.
The {\tt reduce} function in TAIL uses an associative binary operator to reduce an array of rank
$\gamma+1$ to an array of rank $\gamma$ by reducing along the inner-most dimension\cite{ElsmanDybdal:Array:2014}.
The Futhark reduce on the other hand reduces each array in the outer array, i.e. it reduces along the outer-most dimension\cite{TroelsHenriksen}.
 
We have adopted the same approach as with each by using nested maps to map the reduce on the innermost dimension.
 
For example reducing an array of rank 2 emits the following code:
 
\begin{lstlisting}[numbers=none,frame=none]
reduce(+,a)     =>      map(fn x => _reduce_(+,x), a)
\end{lstlisting}


\paragraph{The zipWith operator}
The zipWith operator applies a scalar binary operator on pairs of elements from two arrays of the same shape two
produce a third array of the same shape as the input arrays \cite{ElsmanDybdal:Array:2014}.
 
To do this in Futhark we use the zip function to convert two arrays to an array of tuples and map the binary operator on that array of tuples \cite{TroelsHenriksen}.


\paragraph{The reshape operator} 
%reshape gets as argument the return type.\\
%It is not possible to reshape something that has length 0. It is possible in aplt but we do not support it in our implementation. \\
The reshape operator also has quite unique semantics in TAIL, if the dimensions of reshape don't match the dimensions of the array, the
array is either truncated or the elements are repeated until the array is long enough \cite{ElsmanDybdal:Array:2014}.
Futhark has a reshape function that only works for arrays of the correct dimensions \cite{TroelsHenriksen}.

To actually change the rank of the array we first ensure that the array is the correct size and then use the Futhark reshape
function to do the final step.

To adjust the size we operate on the flat representation of the array, this is easy to produce using Futhark reshape.

To adjust the size of the array we use the previously defined library function {\tt reshap1}. Actually we use the variant with
the correct type, this type is conveniently available in the instance list.

We have used this approach throughout our compiler, e.g. the take operator is implemented similarly.

\paragraph{The transp operator} 
There exists a {\tt transpose(a)} function in Futhark and the reason for not using it to implement the TAIL {\tt transp} is that the Futherk {\tt transpose} have as default that it transposes ?????????????????????????
transp2: only takes literals in transpose dimentions because that is all futhark exepts in rearrange but transp2 in tail cork in other things however we do not support that so one should be aware of this limitation.

\paragraph{The cat operator} 
% why the hell don't we use transpose/rearrange to compile cat?!?! does anyone remember the reason

\paragraph{The take and drop operators} 
The {\tt take} operator in TAIL has very unique semantics, for a positive argument that is less than the size of the array it behaves as one would suspect i.e. it returns the first n elements of the array.
For a negative argument {\tt take} returns the last n elements of the array.
If there are not enough elements in the array, {\tt take} pads with zeros.

In a similar fashion to the TAIL {\tt reshape} function we have used library functions do most of the work.
We flatten the array, let the library function work on the flat representation and finally reshape it to the desired shape.
This approach has all the benefits mentioned earlier.

\paragraph{The cons and snoc operators} takes an array of rank $\gamma$ and an array of rank $\gamma+1$ and concatinates the elements of the 
array of rank $\gamma$ in the front of the elements of the array of rank $\gamma +1$. This result in an array of rank $\gamma+1$. 
The idea behind the compilation of the function snoc was to transpose the two arrays, then concating the arrays and then transposing the resulting array again. That way we would get the desired result of the nth elements from the first array added to the nth element of the second array. However the Futhark transpose function differs slightly from the wished functionality in that. ...\\

\paragraph{The iota operator} 
Due to the fact that the 1-indexing is used in TAIL and 0-indexing is used in Futhark the curried $+1$ is mapped onto the elements of the array created by using the {\tt iota} function of Futhark. 

\paragraph{Lambda expressions} 
% There is more.... than one lambda compilation/translation

The higher order operators {\tt each, eachV, reduce, zipWith} take functions as arguments and these functions are handled by the
entries marken with the $fn$ subscript. Lambda expressions with one argument are mapped to the same in Futhark.
In Futhark lambda expressions need type annotations both for the argument and the return type. This return type is provided by
the context in which the lambda is used. Namely the the type informations is present in the instance lists of the 
enclosing operator call, be it {\tt each}, {\tt reduce} or {\tt zipWith}. Arguments are already annotatated with types in TAIL so
those are simply compiled to Futhark types and passed to the resulting lambda.
Althougn the syntax of TAIL permits lambda expressions anywhere a regular expression could be used (as long as the type is correct),
the TAIL compiler will inline all functions bound to variables when compiling form APL. This means that functions can only occur
inside of the aforementioned operator call and as such this is the only case we support.

The only exception to the rule mentioned above is function currying.
In TAIL currying is used if lambda expressions are to take more than one argument while Futhark does not support currying but
spports mulit-argument lambdas instead. Since the highest number of arguments that can be used is two (in {\tt zipWith}) we have
restricted the compiler to this special case which simplfies the compilation.
The actual body of the function is compiled using the expression rule.
If the function argument is an identifier we use the $op$ and $fun$ rules to compile them.
%They need return type
%Curried lambdas are mapped to multi-argument lambdas 
%We only need two arguments at most
%We compile the bodies using the regular scheme
%If the kernel is an identifier the fun or op translations are used.

\section{Implementation}
\label{sec:impl}
In this section a Haskell implementation of the compilation scheme is presented. This compiler is devided into three parts: a parser, a compiler that transforms the TAIL abstract syntax three (AST) returned by the parser to a Futhark AST and pretty printer that given the Futhark AST prints the Futhark source code. 

\subsection{The parser}
%How we adapted the parser
%The parser that we make use of was created in a precious project \cite{APLACC}.
The parser used in this project was made previusly in another project \cite{APLACC} and therefore not a main part of this project. Because of the ungoing development of the TAIL language however a few changes had to be done to update the parser to work on the latest version of the language. \\

We had to extend the abstarct syntax three to include bools and chars. 
We changes type constructors from previusly ShT (shape type), SiT (singleton integer type), and ViT (single element vector type) that all just took rank
to VecT (vector type) that takes basic type and rank, S (singleton integers and booleans), and SV (single element vectors) that take rank. 
This meant updating the parser to read angles ([]).

The parser is located in the {\tt aplacc } directory of the project: 
The updated code for the compiler can be found in Appendix \ref{app:parser}.

\subsection{The compiler}
The main part of the compiler is placed in {\tt tail2futhark/src/Tail2Futhark/Compile.hs} and transforms the TAIL AST that are returned by the {\tt aplacc} parser to a Futhark AST. The Futhark AST is placed in {\tt tail2futhark/src/Tail2Futhark/Futhark/AST.hs}.

The implementation of the compiler is very close to the compilation presented in the compilation scheme in Section  \ref{sec:scheme}. 

% friske navne - impl detalje - 
% indput fra fil / standard
% 

The source code can be found in its entirety can be found in Appendix \ref{app:compiler}.

\subsection{Pretty print}
The final part of the compiler is the pretty printer located at {\tt tail2futhark/src/
Tail2Futhark/Futhark/Pretty.hs}. 
The pretty printer takes a Futhark AST and transforms the abstract representation of the componants of the AST to correct Futhark source code. 

\subsection{Testing}
We have applied two types of testing in our project. One if a form of correctness test set op as an automated test
framework that will be descussed here. The otheris is to test the efficiency of the generated code in form of benchmarks and will be descussed in Section \ref{sec:benchmarks}. \\


We assume that the compiler producing TAIL code from APL programs returns the correct result. We therefore use the results from running the {\tt apltail} compiler on APL prigrams to compare our own test results to. All tests are originaly written in APL code. Then the {\tt apltail} compiler was used to generate TAIL programs. We did this to ensure that the programs we testet up against was indeed correct TAIL and that no error was introduced by writing TAIL code ourselves. Also, TAIL was designed as

The test framework is made using Cabal \cite{cabal} for manageing external libraries,  Tasty  \cite{tasty}, Tasty-Goldern \cite{tasty-golden}  .. \\

For building our project and managing external libraries we have used the cabal package \cite{cabal}. This is a very common thing to
do in Haskell projects REFERENCE OR REMOVE!! and should make it easy for anyone to build our code.
We use the tasty package \cite{tasty} which provides a test framework that we use to implement our tests. Furthermore we have used the
package tasty-golden \cite{tasty-golden} which is a plug-in for the tasty framework that allows to test against "golden" files.
A lot of projects implement their own test frameworks and we could have done the same.
We chose not to do so as this freed us to use our resources on developing the compiler instead of developing and maintaining a
test framework which could prove time consuming.

The above mentioned framework enabled us to run the tests wehenever new functionality was added and thereby check to see that the new functionality had not introduced bugs that effected the old. \\
Whenever a function was implemented during the development process test cases would be added to the framework along with the alredy existing ones. These tests are all run using our implementation and compaired to the correct output.
We also added a number of more throrough tests at the end of the project in order to see if the function:

\begin{itemize}
\item works on different data types (both base types and rank)
\item work on edgecases
\item works on positive and negative input
\item function correct in all branches in if-then-else expressions
\end{itemize}
In order to thoroughly test the compiler all functions should be have specific test that test one of each of the above things
that meaningfully apply to the function however due to time restrains we have chosen to focus on a smaler subset. \\

Because we have only implemented a subset of TAIL not all TAIL programs can be compiled. 


We have not testet for or taken into account the possibility of TAIL code that are incorrect as it is generated by a compiler and only used as an intermidiate language. 

Based on the results of the test we assume our implementation works as expected on the subset of TAIL we have implemented. 
Because of the importance of the multidimentional arrays for the language we have testet each function on input of 1 dimention and input of at least 2 dimentions. 

%In order to test the correctness of the the generated code we have set up a test using the Cabal framework to make automatet tests that take the TAIL code though the tail2futhark compiler and the Futhark compiler and compair the result from the Futhark compiler with a premade result file containing the correct result. The automated test made it possible to run all tests whenever we did an alteration to the compiler. 
%Running the tests every time we made an alteration enabled us to check if the new alteration had created a problem with the work we had allredy done. \\

We have the tests in a directory called {\tt test/ourtests} in the {\tt tail2futhark} project. \\

%We have not done thorough testing on all the fuctions implemented in the compiler as that is a very time consuming task. 


\section{Benchmarks}
\label{sec:benchmarks}
We have used benchmarks to mesure preformance of the generated Futhark code by comparing it with the TAIL code.
Because no parallel backend are finished for either TAIL or Futhark we use a sequential backend for both languages. \\

The benchmarks used to test the compiled code is all origianaly written in APL. They are then compiled using the {\tt apltail} compiler to TAIL source code and also using the same compiler to an executable file. The TAIL source code was also compiled using the Tail2Futhark compiler to Futhark source code and then using the Futhark compiler to an executable file. This was done automatically by running a make file on the directory containing all the benchmarks.
Then the efficiency of the generated code was tested using {\tt time} on the executable TAIL and Futhark version of the files and the results compaird. In order to have data big enough to level out any initial overhead we ....\\

\subsection{Matrix multiplication}

One of the benchmarks we used was matrix multiplication. The code in TAIL can be seen below. 

\begin{lstlisting}
let v0:[int]2 = reshape{[int],[1,2]}([3,2],iotaV(5)) in
let v1:[int]2 = transp{[int],[2]}(v0) in
let v6:[int]3 = transp2{[int],[3]}([2,1,3],
                     reshape{[int],[2,3]}([3,3,2],v0)) in
let v12:[int]3 = transp2{[int],[3]}([1,3,2],
                     reshape{[int],[2,3]}([3,2,3],v1)) in
let v17:[int]2 = reduce{[int],[2]}(addi,0,
                zipWith{[int,int,int],[3]}(muli,v6,v12)) in
let v22:[int]0 = reduce{[int],[0]}(muli,1,
                 reduce{[int],[1]}(addi,0,v17)) in
i2d(v22)
\end{lstlisting}

It becomes the following Futhark code when run through the compiler...
.
\begin{lstlisting}
futhark code here
\end{lstlisting}

In order to have data big enough to messure the performance of the TAIL executable file and the Futhark executable file the program code was run on a matrix that was 10.000 x 10.000. 
The result of that is...

\section{Discussion}
% Methods used
% Library functions
%% behrænsning kunne have været hvis vi havde valgt at implementere faste libraryfunctions en for hver rank og type. 
% Polymorphism could have been nice
% How could we have tested more throughly
% ...

\subsection{Polymophism}
\subsection{Methods}
\subsection{Limitations}

\section{Conclusion}

%%%%% references %%%%%
\bibliography{references}{} 
\bibliographystyle{plain}

\appendix
\section{Parser source code}
\label{app:parser}

\section{Compiler source code}
\label{app:compiler}

\section{Pretty printer source code}
\label{app:pretty}
\end{document}
